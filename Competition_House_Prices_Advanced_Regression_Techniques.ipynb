{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python",
      "version": "3.6.3",
      "pygments_lexer": "ipython3",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Competition:House Prices: Advanced Regression Techniques",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "5DX8n9SNvMsp",
        "sKBFKy_jvMuT",
        "g39vNUxavMud",
        "eMxQ6iGmvMuk",
        "a8UTSVi5vMwS",
        "BcA-E4kFvMxg",
        "FzN-DhrZvMxx"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaynarayan94/Competition-Codes/blob/master/Competition_House_Prices_Advanced_Regression_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03rqsLN7vSQb",
        "colab_type": "text"
      },
      "source": [
        "## House prediction of Ames House dataset\n",
        "\n",
        "### Public Score : 0.11679 || In Top 17% Winner \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c9b1d5dff21d39260eb47af6fe7aac4bd03be233",
        "_execution_state": "idle",
        "_cell_guid": "2dbccbd6-138b-4f1b-9b23-fd60c7525c14",
        "trusted": true,
        "id": "hMkxWxz7vMrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import some necessary librairies\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "sns.set_style('darkgrid')\n",
        "import warnings\n",
        "def ignore_warn(*args, **kwargs):\n",
        "    pass\n",
        "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew #for some statistics\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
        "\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\")) #check the files available in the directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0e694d13459e3e200f6e2c6333c887cbad779ba9",
        "_execution_state": "idle",
        "_cell_guid": "59617b4b-d797-44ce-9142-05fbfd36aada",
        "trusted": true,
        "id": "WoALjYB0vMrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now let's import and put the train and test datasets in  pandas dataframe\n",
        "\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3a32f51460a02fbe7a9122db55a740eb378dda97",
        "_execution_state": "idle",
        "_cell_guid": "3678529f-9d76-4853-88c5-4b2d230a85b6",
        "trusted": true,
        "id": "um6hVx8mvMrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##display the first five rows of the train dataset.\n",
        "train.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "816b1463b3dd0daf44949a1fa15ebfbc0e2f1235",
        "_execution_state": "idle",
        "_cell_guid": "ff37c1ba-8679-49e0-b3c8-9c53d01b1b04",
        "trusted": true,
        "id": "XhyuFTzavMrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##display the first five rows of the test dataset.\n",
        "test.head(5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "687813c270cbfdedccc7a9e4ec9fbb78a99d54ed",
        "_execution_state": "idle",
        "_cell_guid": "b24451a1-fb8c-4094-ad0b-0940469d07fc",
        "trusted": true,
        "id": "O4O5B4DQvMr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the numbers of samples and features\n",
        "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
        "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
        "\n",
        "#Save the 'Id' column\n",
        "train_ID = train['Id']\n",
        "test_ID = test['Id']\n",
        "\n",
        "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
        "train.drop(\"Id\", axis = 1, inplace = True)\n",
        "test.drop(\"Id\", axis = 1, inplace = True)\n",
        "\n",
        "#check again the data size after dropping the 'Id' variable\n",
        "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
        "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "228cb602f1c7a47d3c5250514cab57f7e7bc75e5",
        "_execution_state": "idle",
        "_cell_guid": "7d5829c4-b2f1-4ef3-8b02-11f02eb7aabf",
        "id": "rnOoVfKEvMr3",
        "colab_type": "text"
      },
      "source": [
        "#Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "32b12bca723c5e867f7d7a7e179ff934a5fcdf30",
        "_execution_state": "idle",
        "_cell_guid": "465043f2-d687-4b1f-a6b4-1036859dfeb0",
        "id": "aD79Kv75vMr6",
        "colab_type": "text"
      },
      "source": [
        "Let's explore these outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "edf186dc5169e450392ee8f809cc3de5d10d7dbd",
        "_execution_state": "idle",
        "_cell_guid": "30304b82-5846-4142-bc31-b629158fb040",
        "id": "9jKjeteMvMr7",
        "colab_type": "text"
      },
      "source": [
        "We can see at the bottom right two with extremely large GrLivArea that are of a low price. These values are huge oultliers.\n",
        "Therefore, we can safely delete them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-7vv6OpzvMsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "areas = ['GrLivArea', 'GarageArea', 'TotalBsmtSF']\n",
        "\n",
        "for columns in areas:\n",
        "  plt.figure()\n",
        "  sns.lmplot(y = 'SalePrice', x = columns, data = train);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "583bb417102d7bebb4aaf14bcb1aebcae86443bb",
        "_execution_state": "idle",
        "_cell_guid": "6c5780b2-d4a8-42d9-b902-c6a23eef7d99",
        "trusted": true,
        "id": "CKZm1JBhvMsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deleting outliers\n",
        "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
        "\n",
        "#Check the graphic again\n",
        "sns.lmplot(x = 'GrLivArea', y = 'SalePrice',data = train)\n",
        "plt.ylabel('SalePrice', fontsize=13)\n",
        "plt.xlabel('GrLivArea', fontsize=13)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0f186c5806f14de1e9ea46ece78a4bed2a6830a7",
        "_execution_state": "idle",
        "_cell_guid": "e24be1ff-e186-4d0f-9ba1-64195c0eec4d",
        "id": "Kd6ceg0qvMsa",
        "colab_type": "text"
      },
      "source": [
        "#### We can see there are few outliers and we will deal with them later.\n",
        "\n",
        "#### Let us see how the SalePrice is related categorical variables like Overall quality and OverallCond of the plot\n",
        "\n",
        "###Note : \n",
        " Outliers removal is note always safe.  We decided to delete these two as they are very huge and  really  bad ( extremely large areas for very low  prices). \n",
        "\n",
        "There are probably others outliers in the training data.   However, removing all them  may affect badly our models if ever there were also  outliers  in the test data. That's why , instead of removing them all, we will just manage to make some of our  models robust on them. You can refer to  the modelling part of this notebook for that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7IqhyRDxvMsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.boxplot(x = 'OverallQual', y= 'SalePrice',data = train)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qtOlrZBevMsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x = 'OverallCond', y = 'SalePrice', data = train)\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPiRYhpvvMsk",
        "colab_type": "text"
      },
      "source": [
        "#### We can see that with better house conditions the prices increase. \n",
        "\n",
        "#### Let us see how the house prices have changed over the years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y4HSrwKBvMsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(21,12))\n",
        "\n",
        "ax = sns.boxplot(x = 'YearBuilt', y = 'SalePrice', data = train)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation = 90, ha = 'right', fondsize = 12)\n",
        "plt.xticks(rotation =90)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DX8n9SNvMsp",
        "colab_type": "text"
      },
      "source": [
        "#### We can see the house prices have increased over the years and though a boxplot we can have an understanding of their distributions.\n",
        "\n",
        "### Let us find the correlation between the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pMH1tjp_vMsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = train.corr()\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "k = 10 #number of variables for heatmap\n",
        "cols = corr.nlargest(k, 'SalePrice')['SalePrice'].index\n",
        "cm = np.corrcoef(train[cols].values.T)\n",
        "sns.set(font_scale=1.25)\n",
        "hm = sns.heatmap(cm, cbar=True, annot=True, square=True,yticklabels=cols.values, xticklabels=cols.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "886ad7c816f4c1fd9afda53b10990baf987e86d8",
        "_execution_state": "idle",
        "_cell_guid": "f4dcb348-634e-4010-b0a1-27976a1d8353",
        "id": "oUGTgzxnvMtq",
        "colab_type": "text"
      },
      "source": [
        "##Target Variable\n",
        "\n",
        "**SalePrice** is the variable we need to predict. So let's do some analysis on this variable first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "be3b0157031685ed3dbc31a657ba712312691830",
        "_execution_state": "idle",
        "_cell_guid": "a17ad845-6fca-4d47-8e44-7c4c44f0427d",
        "trusted": true,
        "id": "FEF1U-r5vMts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(train['SalePrice'] , fit=norm);\n",
        "\n",
        "# Get the fitted parameters used by the function\n",
        "(mu, sigma) = norm.fit(train['SalePrice'])\n",
        "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
        "\n",
        "#Now plot the distribution\n",
        "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
        "            loc='best')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('SalePrice distribution')\n",
        "\n",
        "#Get also the QQ-plot\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(train['SalePrice'], plot=plt)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1da2d9831ae6c94b3f6304185f02896a9ee40aa5",
        "_execution_state": "idle",
        "_cell_guid": "313a535c-86c4-4db5-96de-6f65bc4adc2f",
        "id": "lVPdvbMYvMtv",
        "colab_type": "text"
      },
      "source": [
        "The target variable is right skewed.  As (linear) models love normally distributed data , we need to transform this variable and make it more normally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "421775277fdab4e5a05f74aa4ea92e712a743928",
        "_execution_state": "idle",
        "_cell_guid": "8df72eef-77de-4a71-aa6a-4b91784a7232",
        "id": "fOjMlZtDvMtw",
        "colab_type": "text"
      },
      "source": [
        " **Log-transformation of the target variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "719cf6a9dca56cc529e97af21816d291fa8bd8c0",
        "_execution_state": "idle",
        "_cell_guid": "21b3a0ad-bd68-49aa-a3d7-40a30b3c59dc",
        "trusted": true,
        "id": "KEWV5a4wvMty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
        "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
        "\n",
        "#Check the new distribution \n",
        "sns.distplot(train['SalePrice'] , fit=norm);\n",
        "\n",
        "# Get the fitted parameters used by the function\n",
        "(mu, sigma) = norm.fit(train['SalePrice'])\n",
        "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
        "\n",
        "#Now plot the distribution\n",
        "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
        "            loc='best')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('SalePrice distribution')\n",
        "\n",
        "#Get also the QQ-plot\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(train['SalePrice'], plot=plt)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "991e699566f4292490fda326703baa33ce09173f",
        "_execution_state": "idle",
        "_cell_guid": "51620309-727a-4445-a96a-d9851880d31f",
        "id": "xL0wDhgovMt5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "827a86d65c6d176f4af55224b91b44a47966652d",
        "_execution_state": "idle",
        "_cell_guid": "802df76d-0e0b-4868-ba16-91335568d2d7",
        "id": "dF3I9ADsvMt6",
        "colab_type": "text"
      },
      "source": [
        "1. The skew seems now corrected and the data appears more normally distributed. \n",
        "\n",
        "## Features engineering\n",
        "\n",
        "let's first  concatenate the train and test data in the same dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "efc576211e4eed962f04cd94d901c667e6912528",
        "_execution_state": "idle",
        "_cell_guid": "1bd3e9b9-2f42-4251-aadd-5ced84eb1a27",
        "trusted": true,
        "id": "YH3GrKlhvMt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "y_train = train.SalePrice.values\n",
        "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
        "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
        "print(\"all_data size is : {}\".format(all_data.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "abe25f3032a0bed179d58d5911cb42d97b35841b",
        "_execution_state": "idle",
        "_cell_guid": "9ce95008-a3b9-43fa-bc4e-649ca0f43768",
        "id": "R2cYRXdMvMuD",
        "colab_type": "text"
      },
      "source": [
        "## Let's deal with missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f97d25548ec8f6c02e2d1ee5a6df6c3d107fdf53",
        "_execution_state": "idle",
        "_cell_guid": "501b465f-8c80-4b93-81d0-a5d41e08d235",
        "trusted": true,
        "id": "Fn7W9elDvMuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NA_values = all_data.isna().sum().sort_values(ascending=False)[:34]\n",
        "\n",
        "NA = pd.concat([NA_values,(NA_values/len(all_data)*100)],axis=1)\n",
        "\n",
        "NA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2eb6e1361884db6a4f65afc3b158fcbe85c2392e",
        "_execution_state": "idle",
        "_cell_guid": "1c80610d-8f19-43c8-bd54-7d786b0dca49",
        "trusted": true,
        "id": "O3c2gKRovMuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "ax = sns.barplot(y = NA.iloc[:,0], x = NA.index)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "41a6b40f8f03212a624f54167cad456a9f193f93",
        "_execution_state": "idle",
        "_cell_guid": "cd681698-02d2-473e-bfc8-2d98a1353a18",
        "id": "sKBFKy_jvMuT",
        "colab_type": "text"
      },
      "source": [
        "###Imputing missing values \n",
        "\n",
        "We impute them  by proceeding sequentially  through features with missing values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_Xe-XoXcvMuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Similarly if there is no basement then the following values would be 0 \n",
        "NA_zero = ['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\n",
        "           'MasVnrArea']\n",
        "\n",
        "#Similarly NA indicates no feature here and we hence can fill it with 'None'\n",
        "Na_none = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu','GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', \n",
        "           'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType']\n",
        "\n",
        "for col in NA_zero:\n",
        "    all_data[col] = all_data[col].fillna(0)\n",
        "\n",
        "#Similarly None for categorical attributes\n",
        "for col in Na_none:\n",
        "    all_data[col] = all_data[col].fillna('None')\n",
        "\n",
        "    \n",
        "#Since area of a street is connected to the house property we can fill in missing values by the median LotFrontage of the neighborhood.\n",
        "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
        "    \n",
        "#Here 'RL' is the most common value and we can fill this in using mode\n",
        "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
        "\n",
        "# For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA so it is safe to drop it\n",
        "all_data = all_data.drop(['Utilities'], axis=1)\n",
        "\n",
        "# Data description says NA means typical\n",
        "all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
        "\n",
        "#It has one NA value. and is mostly 'SBrkr', we can use mode imputation for the missing value\n",
        "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
        "\n",
        "#Just like electrical it has one missing value\n",
        "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
        "\n",
        "#Same as above\n",
        "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
        "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
        "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
        "\n",
        "#Na most likely means No building class\n",
        "all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g39vNUxavMud",
        "colab_type": "text"
      },
      "source": [
        "#### Let us see if there are any null values remaining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b091fa2ebef19425019e2e550410d0376b9e9fac",
        "_execution_state": "idle",
        "_cell_guid": "0adf05cf-ce60-4169-805c-ca776e60e85a",
        "trusted": true,
        "id": "8MT10afEvMuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data.isnull().sum().sort_values(ascending = False).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "360f518886ac45afe2963b9b53edb17c2be4a130",
        "_execution_state": "idle",
        "_cell_guid": "78266762-5180-44fa-a630-b808706800d4",
        "id": "eMxQ6iGmvMuk",
        "colab_type": "text"
      },
      "source": [
        "It remains no missing value.\n",
        "\n",
        "###More features engeneering\n",
        "\n",
        "**Transforming some numerical variables that are really categorical**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cc7557817a4442e799e4e4c84dd1efd8bd08867a",
        "_execution_state": "idle",
        "_cell_guid": "a52dc2f9-ca02-4024-987a-165ce630b356",
        "trusted": true,
        "id": "hPRnCtfovMum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MSSubClass=The building class\n",
        "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
        "\n",
        "\n",
        "#Changing OverallCond into a categorical variable\n",
        "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
        "\n",
        "\n",
        "#Year and month sold are transformed into categorical features.\n",
        "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
        "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c4743ffb7fbb050edca7c77dc7cb6520577c1398",
        "_execution_state": "idle",
        "_cell_guid": "9f80c0e7-3f3f-45c5-b111-e36f4e31e814",
        "id": "2ou0vTicvMut",
        "colab_type": "text"
      },
      "source": [
        "**Label Encoding some categorical variables that may contain information in their ordering set** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fdb5ddf0a49a3c6df303c569c9f3509c79ac8b61",
        "_execution_state": "idle",
        "_cell_guid": "81c97efb-4f76-4e87-861a-10a60ab5c84b",
        "trusted": true,
        "id": "PwvI3HzivMut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
        "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
        "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
        "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
        "        'YrSold', 'MoSold')\n",
        "# process columns, apply LabelEncoder to categorical features\n",
        "for c in cols:\n",
        "    lbl = LabelEncoder() \n",
        "    lbl.fit(list(all_data[c].values)) \n",
        "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
        "\n",
        "# shape        \n",
        "print('Shape all_data: {}'.format(all_data.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9976d6288bc183d443fbccc2bde439d5bc3a87b1",
        "_execution_state": "idle",
        "_cell_guid": "a4879ef7-ab0d-4955-bc48-7ebcfa04b3bd",
        "id": "T2AfjMTvvMux",
        "colab_type": "text"
      },
      "source": [
        "**Adding one more important feature**\n",
        "\n",
        "Since area related features are very important to determine house prices, we add one more feature which is the total area of basement, first and second floor areas of each house"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "208f8d22188786227fff4a978dc3b11b4e1ffd90",
        "_execution_state": "idle",
        "_cell_guid": "fc1a8f1a-f003-4538-8e60-d819f46362a3",
        "trusted": true,
        "id": "xZvvt4R4vMuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding total sqfootage feature \n",
        "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "aa36d6e3253e354b46d9c9c6f2e8a4089c76be16",
        "_execution_state": "idle",
        "_cell_guid": "91c73aad-82d1-4301-b540-b2f69dc13902",
        "id": "Whrc5VoMvMvB",
        "colab_type": "text"
      },
      "source": [
        "**Skewed features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "53c471c7008c66590f257e70866f8a3037813f13",
        "_execution_state": "idle",
        "_cell_guid": "c5972a73-7e86-4164-a9d6-58432dae1933",
        "trusted": true,
        "id": "5pVzC5tXvMvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
        "\n",
        "# Check the skew of all numerical features\n",
        "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
        "print(\"\\nSkew in numerical features: \\n\")\n",
        "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
        "skewness.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cf63bdc9f4f80d81f1bfa14f89d65ff104d45e5b",
        "_execution_state": "idle",
        "_cell_guid": "9f110087-b707-4073-a1df-0a0a9d6ccbd3",
        "id": "Lhvj1A16vMvF",
        "colab_type": "text"
      },
      "source": [
        "**Box Cox Transformation of (highly) skewed features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "eab0b4c0a85ae2fbe1bdeea0eedd113904ef3eb1",
        "_execution_state": "idle",
        "_cell_guid": "d1d18243-42d8-4a21-808d-784c21e53973",
        "id": "b9OfPryhvMvG",
        "colab_type": "text"
      },
      "source": [
        "We use the scipy  function boxcox1p which computes the Box-Cox transformation of **\\\\(1 + x\\\\)**. \n",
        "\n",
        "Note that setting \\\\( \\lambda = 0 \\\\) is equivalent to log1p used above for the target variable.  \n",
        "\n",
        "See [this page][1] for more details on Box Cox Transformation as well as [the scipy function's page][2]\n",
        "[1]: http://onlinestatbook.com/2/transformations/box-cox.html\n",
        "[2]: https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.special.boxcox1p.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "969fdff338ef46f064d8f855782c96d322a264b1",
        "_execution_state": "idle",
        "_cell_guid": "d8ebce87-c55d-46c6-8f06-8b34116d7370",
        "trusted": true,
        "id": "SyBdSYIPvMvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skewness = skewness[abs(skewness.Skew) > 0.75]\n",
        "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
        "\n",
        "from scipy.special import boxcox1p\n",
        "skewed_features = skewness.index\n",
        "lam = 0.15\n",
        "for feat in skewed_features:\n",
        "    #all_data[feat] += 1\n",
        "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
        "    \n",
        "#all_data[skewed_features] = np.log1p(all_data[skewed_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5a13a6e2a3e48975de9129d1593bd38df44a1069",
        "_execution_state": "idle",
        "_cell_guid": "39639caf-31a4-4401-a663-0ba9536b39bf",
        "id": "ObW9_DG9vMvL",
        "colab_type": "text"
      },
      "source": [
        "**Getting dummy categorical features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "acd44e283867425257ffd1fb2f4893cdbff43f67",
        "_execution_state": "idle",
        "_cell_guid": "c8e63516-e4e2-4f36-a60e-1c8316392c60",
        "trusted": true,
        "id": "xwTDLuufvMvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "all_data = pd.get_dummies(all_data)\n",
        "print(all_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fe9d78c7e37142ee8089826eca3065e0fa5803c1",
        "_execution_state": "idle",
        "_cell_guid": "243cf047-c2ba-4ae5-a531-22ef9b7cfbfe",
        "id": "rkiQzPL4vMvP",
        "colab_type": "text"
      },
      "source": [
        "Getting the new train and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "89e464095544a53177d5a009b914ba4c660072a7",
        "_execution_state": "idle",
        "_cell_guid": "0a75646f-1974-40ad-a085-ff7bc08454a5",
        "trusted": true,
        "id": "WHQOtWmTvMvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = all_data[:ntrain]\n",
        "test = all_data[ntrain:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "10aab4cee97832560e2627a490e01e80c0ffb814",
        "_execution_state": "idle",
        "_cell_guid": "461af83d-a928-4645-8512-5e4dbcaf7be0",
        "id": "58FJoa6gvMvX",
        "colab_type": "text"
      },
      "source": [
        "#Modelling\n",
        "\n",
        "**Import librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "fc664fbe27561a3697d0210921107b0e14b7d211",
        "_execution_state": "idle",
        "_cell_guid": "135e8ac5-ce46-4a5f-b205-13f827ef33b8",
        "trusted": true,
        "id": "V2GqUPMEvMvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dc0d7a3013f349988b3f2c84a6c130d6ad350170",
        "_execution_state": "idle",
        "_cell_guid": "4a2b5181-44f2-4c74-b482-aae0f5afc25a",
        "id": "ACO0xnqWvMvg",
        "colab_type": "text"
      },
      "source": [
        "**Define a cross validation strategy**\n",
        "\n",
        "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data.<br> That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5c12551d092a6c5cf32d86398b054da7af3047b8",
        "_execution_state": "idle",
        "_cell_guid": "f396260b-e182-4a87-9a2a-b92b9375ea6f",
        "trusted": true,
        "id": "uqeqNPMlvMvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Validation function\n",
        "n_folds = 5\n",
        "\n",
        "def rmsle_cv(model):\n",
        "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
        "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
        "    return(rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "643ae2c4a88576ebbd55824ce8e654486087a6e0",
        "_execution_state": "busy",
        "_cell_guid": "42e1565e-77a1-41a7-ac31-893e405d34ad",
        "id": "JvvHeX5vvMvm",
        "colab_type": "text"
      },
      "source": [
        "##Base models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "370125198a0cbbc9336cbf179f00a2ebb02cb063",
        "_execution_state": "idle",
        "_cell_guid": "578f088d-1a84-41cb-b945-ec64800f2308",
        "id": "mLa57CSavMvn",
        "colab_type": "text"
      },
      "source": [
        "-  **LASSO  Regression**  : \n",
        "\n",
        "Lasso uses L1 regularization technique <br>\n",
        "It is generally used when we have more number of features, because it automatically does feature selection.\n",
        "\n",
        "This model may be very sensitive to outliers. So we need to made it more robust on them. For that we use the sklearn's  **Robustscaler()**  method on pipeline "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2a50c954cb771d350c3092c3658486ba4d22aba5",
        "_execution_state": "idle",
        "_cell_guid": "03f45cb7-0a40-45ea-94e8-64fd7ff1e8f6",
        "trusted": true,
        "id": "bXXNWA2PvMvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "30e9756cf63991715b48e8c53bc57906fc76f380",
        "_execution_state": "idle",
        "_cell_guid": "2c826f7b-ac66-421c-a7ae-29dfdd765bdb",
        "id": "qAmGiSB7vMv0",
        "colab_type": "text"
      },
      "source": [
        "- **Elastic Net Regression** :\n",
        "\n",
        "Elastic net is basically a combination of both L1 and L2 regularization. So if you know elastic net, you can implement both Ridge and Lasso by tuning the parameters. So it uses both L1 and L2 penality term <br>\n",
        "<br>\n",
        "We have a bunch of correlated independent variables in a dataset, then elastic net will simply form a group consisting of these correlated variables. Now if any one of the variable of this group is a strong predictor (meaning having a strong relationship with dependent variable), then we will include the entire group in the model building, because omitting other variables (like what we did in lasso) might result in losing some information in terms of interpretation ability, leading to a poor model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b614cf1bdee86a3b1cbdde05298f9f7ae023799b",
        "_execution_state": "idle",
        "_cell_guid": "e635cc7e-caeb-4f8b-ae78-c41f8eb0be59",
        "trusted": true,
        "id": "qlEVF8_kvMv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0775061bb477242f1332a048778e879ca540a216",
        "_execution_state": "idle",
        "_cell_guid": "7aae5316-4e32-4203-bff5-3b38c1f657c3",
        "id": "-1mpuN61vMv5",
        "colab_type": "text"
      },
      "source": [
        "- **Kernel Ridge Regression** :\n",
        "\n",
        "Kernel ridge regression is essentially the same as usual ridge regression, but uses the kernel trick to go non-linear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3199c83513d93407c818ce1ed43c6c52e7f5a8c6",
        "_execution_state": "idle",
        "_cell_guid": "805343d9-0af6-43a2-a351-c0b25c62fcf0",
        "trusted": true,
        "id": "DDb1T_YCvMv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "14b60a7e4296cccb39042c9c625a1480d59a01c1",
        "_execution_state": "idle",
        "_cell_guid": "5a66c27c-be80-4ec0-8953-eaeb2a7dd2e7",
        "id": "F17odqI-vMv8",
        "colab_type": "text"
      },
      "source": [
        "- **Gradient Boosting Regression** :\n",
        "\n",
        "Boosting is an ensemble technique where new models are added to correct the errors made by existing models. Models are added sequentially until no further improvements can be made.\n",
        "<br>\n",
        "XGBoost is an implementation of gradient boosted decision trees designed for speed and performance.\n",
        "\n",
        "\n",
        "\n",
        "With **huber**  loss that makes it robust to outliers\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9a983f0f62a0dde7689b20a8e52022bb189478b4",
        "_execution_state": "idle",
        "_cell_guid": "af13332c-fd37-40bb-a078-6bad6caaa2ab",
        "trusted": true,
        "id": "3bqqihMvvMv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
        "                                   max_depth=4, max_features='sqrt',\n",
        "                                   min_samples_leaf=15, min_samples_split=10, \n",
        "                                   loss='huber', random_state =5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "53d7991f7dd03fcd7fb5ab1ec26fcd0614d002d3",
        "_execution_state": "idle",
        "_cell_guid": "d44ac87e-bf01-440b-ab22-b2868eb6ae48",
        "id": "kS3dVOrzvMwA",
        "colab_type": "text"
      },
      "source": [
        "- **XGBoost** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "57c24b596ceb46d6f32ebf9501d672d7e469c15b",
        "_execution_state": "idle",
        "_cell_guid": "ed738a4c-c246-443c-a3c1-39df25f988b7",
        "trusted": true,
        "id": "SSSXVj1cvMwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
        "                             learning_rate=0.05, max_depth=3, \n",
        "                             min_child_weight=1.7817, n_estimators=2200,\n",
        "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
        "                             subsample=0.5213, silent=1,\n",
        "                             random_state =7, nthread = -1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "460f3ccf7d5c33ea9f8a826bbf056d759e7b5119",
        "_execution_state": "idle",
        "_cell_guid": "a43ca74d-093c-4a56-a76c-b3223bf82fbc",
        "id": "oR-TMShTvMwF",
        "colab_type": "text"
      },
      "source": [
        "- **LightGBM** :\n",
        "\n",
        "Light GBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithm, used for ranking, classification and many other machine learning tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4c94cf90f0ef0d350c5e66f3bd397865bfcc61ae",
        "_execution_state": "idle",
        "_cell_guid": "dd84d7db-3f83-4e4e-b02f-7632ca5ee4ac",
        "trusted": true,
        "id": "NvgaaVn8vMwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
        "                              learning_rate=0.05, n_estimators=720,\n",
        "                              max_bin = 55, bagging_fraction = 0.8,\n",
        "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
        "                              feature_fraction_seed=9, bagging_seed=9,\n",
        "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cae4987b8ec89e90a90d7826c4ec98d315cac00b",
        "_execution_state": "idle",
        "_cell_guid": "84ddecce-7671-44e5-919d-97348bf413f4",
        "id": "a8UTSVi5vMwS",
        "colab_type": "text"
      },
      "source": [
        "###Base models scores\n",
        "\n",
        "Let's see how these base models perform on the data by evaluating the  cross-validation rmsle error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7d994349237b9304b0d17719e1af077e69288229",
        "_execution_state": "idle",
        "_cell_guid": "2d0cc958-1654-425c-90ed-1ceb9edd7186",
        "trusted": true,
        "id": "Ih0g8rcwvMwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = rmsle_cv(lasso)\n",
        "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b6d299b9d4a0cdb23ddd8459b3935da2948016d6",
        "_execution_state": "idle",
        "_cell_guid": "7cf6faaf-d69a-4268-b192-a9e60d207c28",
        "trusted": true,
        "id": "pw4TqPZYvMwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = rmsle_cv(ENet)\n",
        "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "437dc093e88d661a369539520af1b4c37d1a0c1a",
        "_execution_state": "idle",
        "_cell_guid": "a1195106-2170-47f2-86a7-c4f3be683aa8",
        "trusted": true,
        "id": "OFOJ0t-hvMw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = rmsle_cv(KRR)\n",
        "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e9d8c4bd191f77d8d275f53c0c1a6cf344151294",
        "_execution_state": "idle",
        "_cell_guid": "43dd152f-7c49-41b6-8f8e-a5864b1e2a71",
        "trusted": true,
        "id": "NfPySfsfvMw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = rmsle_cv(GBoost)\n",
        "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5f52ccf39d01165e61a7c6be8b788be4e58e286b",
        "_execution_state": "idle",
        "_cell_guid": "30738ecc-39f8-44ed-9f42-68518beb7e6a",
        "trusted": true,
        "id": "VmjDKpH7vMxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "score = rmsle_cv(model_xgb)\n",
        "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5cd5377ee097fbc6fd14b42b4ea654221b097e59",
        "_execution_state": "idle",
        "_cell_guid": "41e0eab9-630d-48d3-905b-e4663aad2262",
        "trusted": true,
        "id": "V8vBqcp7vMxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = rmsle_cv(model_lgb)\n",
        "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c6e3a67facbc786ddec2f56b40b4da37726d1be5",
        "_execution_state": "idle",
        "_cell_guid": "96d5979d-73ba-4810-bee2-e1a7a8de57f6",
        "id": "J_I82YB2vMxS",
        "colab_type": "text"
      },
      "source": [
        "##Stacking  models\n",
        "###Simplest Stacking approach : Averaging base models\n",
        "\n",
        "We begin with this simple approach of averaging base models.  We build a new **class**  to extend scikit-learn with our model and also to laverage encapsulation and code reuse ([inheritance][1]) \n",
        "\n",
        "\n",
        "  [1]: https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)\n",
        "  \n",
        "  **Averaged base models class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ff3ee5889bcac40847909c3a71285d2b8f9d431f",
        "_execution_state": "idle",
        "_cell_guid": "49e44ad6-8dc4-4a67-8079-adbac934fec4",
        "trusted": true,
        "id": "mC3ZQ-60vMxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "        \n",
        "    # we define clones of the original models to fit the data in\n",
        "    def fit(self, X, y):\n",
        "        self.models_ = [clone(x) for x in self.models]\n",
        "        \n",
        "        # Train cloned base models\n",
        "        for model in self.models_:\n",
        "            model.fit(X, y)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    #Now we do the predictions for cloned models and average them\n",
        "    def predict(self, X):\n",
        "        predictions = np.column_stack([\n",
        "            model.predict(X) for model in self.models_\n",
        "        ])\n",
        "        return np.mean(predictions, axis=1)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b66ef29c829b7122a2e8e2d187211039570973ac",
        "_execution_state": "idle",
        "_cell_guid": "18209a57-f46d-4ce7-8331-834f419c57f2",
        "id": "PyvWV6nYvMxb",
        "colab_type": "text"
      },
      "source": [
        "**Averaged base models score**\n",
        "\n",
        "We just average four models here **ENet, GBoost,  KRR and lasso**.  Of course we could easily add more models in the mix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "81ce9e148b7e735f465b4b6508511dea44fbf791",
        "_execution_state": "idle",
        "_cell_guid": "d480916f-89e7-4bcc-9b9d-b54492591654",
        "trusted": true,
        "id": "EBdCX1EdvMxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n",
        "\n",
        "score = rmsle_cv(averaged_models)\n",
        "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "421c03673969c6a2dd2253f9d4c503ab1276b105",
        "_execution_state": "idle",
        "_cell_guid": "588f9fd2-0c5e-43cd-8a0a-0271f2468ef7",
        "id": "BGYX6rR5vMxf",
        "colab_type": "text"
      },
      "source": [
        "Wow ! It seems even the simplest stacking approach really improve the score . This encourages \n",
        "us to go further and explore a less simple stacking approch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "01b68302f0ec3af42a70794bc339bf5956ab2569",
        "_execution_state": "idle",
        "_cell_guid": "387761c7-9dc5-41aa-8cda-5315b6a72fbf",
        "id": "BcA-E4kFvMxg",
        "colab_type": "text"
      },
      "source": [
        "###Less simple Stacking : Adding a Meta-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "69f216ce13eb61f0d07403986a2d38b11e18ae6a",
        "_execution_state": "idle",
        "_cell_guid": "cb18e314-968d-4765-942a-5706d0f4f815",
        "id": "H2v5a8xpvMxh",
        "colab_type": "text"
      },
      "source": [
        "In this approach, we add a meta-model on averaged base models and use the out-of-folds predictions of these base models to train our meta-model. \n",
        "\n",
        "The procedure, for the training part, may be described as follows:\n",
        "\n",
        "\n",
        "1. Split the total training set into two disjoint sets (here **train** and .**holdout** )\n",
        "\n",
        "2. Train several base models on the first part (**train**)\n",
        "\n",
        "3. Test these base models on the second part (**holdout**)\n",
        "\n",
        "4. Use the predictions from 3)  (called  out-of-folds predictions) as the inputs, and the correct responses (target variable) as the outputs  to train a higher level learner called **meta-model**.\n",
        "\n",
        "The first three steps are done iteratively . If we take for example a 5-fold stacking , we first split the training data into 5 folds. Then we will do 5 iterations. In each iteration,  we train every base model on 4 folds and predict on the remaining fold (holdout fold). \n",
        "\n",
        "So, we will be sure, after 5 iterations , that the entire data is used to get out-of-folds predictions that we will then use as \n",
        "new feature to train our meta-model in the step 4.\n",
        "\n",
        "For the prediction part , We average the predictions of  all base models on the test data  and used them as **meta-features**  on which, the final prediction is done with the meta-model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5374a729325ac38423ff82891f1cc887f14ba317",
        "_execution_state": "idle",
        "_cell_guid": "bd10661e-6eec-4789-83fa-d55b77619252",
        "id": "hIfBQgiOvMxh",
        "colab_type": "text"
      },
      "source": [
        "**Stacking averaged Models Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9115cf7180ba9491bd0a2c5bd566e18238c9de80",
        "_execution_state": "idle",
        "_cell_guid": "03326750-2442-4e14-8774-6e2ce9330173",
        "trusted": true,
        "id": "hNc5rPGgvMxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
        "    def __init__(self, base_models, meta_model, n_folds=5):\n",
        "        self.base_models = base_models\n",
        "        self.meta_model = meta_model\n",
        "        self.n_folds = n_folds\n",
        "   \n",
        "    # We again fit the data on clones of the original models\n",
        "    def fit(self, X, y):\n",
        "        self.base_models_ = [list() for x in self.base_models]\n",
        "        self.meta_model_ = clone(self.meta_model)\n",
        "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
        "        \n",
        "        # Train cloned base models then create out-of-fold predictions\n",
        "        # that are needed to train the cloned meta-model\n",
        "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
        "        for i, model in enumerate(self.base_models):\n",
        "            for train_index, holdout_index in kfold.split(X, y):\n",
        "                instance = clone(model)\n",
        "                self.base_models_[i].append(instance)\n",
        "                instance.fit(X[train_index], y[train_index])\n",
        "                y_pred = instance.predict(X[holdout_index])\n",
        "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
        "                \n",
        "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
        "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
        "        return self\n",
        "   \n",
        "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
        "    #meta-features for the final prediction which is done by the meta-model\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([\n",
        "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
        "            for base_models in self.base_models_ ])\n",
        "        return self.meta_model_.predict(meta_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5fdbcf5c678b260adf80cf39b0f3bb63a26213e1",
        "_execution_state": "idle",
        "_cell_guid": "da4c9354-b5c2-4994-8ffd-550416a5c4db",
        "id": "jP0_ikcIvMxl",
        "colab_type": "text"
      },
      "source": [
        "**Stacking Averaged models Score**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "10fdbde25e455566637627554269adff7dfec193",
        "_execution_state": "idle",
        "_cell_guid": "03abed3d-205c-411d-89de-b566b7f1f708",
        "id": "Qq5xMc1uvMxl",
        "colab_type": "text"
      },
      "source": [
        "To make the two approaches comparable (by using the same number of models) , we just average **Enet KRR and Gboost**, then we add **lasso as meta-model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f2c78b5950097660d3f8b84bade8d8dbdc3964f2",
        "_execution_state": "idle",
        "_cell_guid": "4db03a27-e9fb-484d-bbfe-2058f16dce77",
        "trusted": true,
        "id": "gFHuSa_IvMxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
        "                                                 meta_model = lasso)\n",
        "\n",
        "score = rmsle_cv(stacked_averaged_models)\n",
        "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0ca396a31059f16aff47e0d53d011865634e101e",
        "_execution_state": "idle",
        "_cell_guid": "61f0f9af-9264-4945-829a-c629ed6a3299",
        "id": "4QvhA8O8vMxr",
        "colab_type": "text"
      },
      "source": [
        "We get again a better score by adding a meta learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "75e8303614ea910f93056a8bdc4cd9cfe62ecd46",
        "_execution_state": "idle",
        "_cell_guid": "1cc6527c-4705-4895-992f-0c3755b27cee",
        "id": "x7dw1o50vMxs",
        "colab_type": "text"
      },
      "source": [
        "## Ensembling StackedRegressor, XGBoost and LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5835af97aef41c60ea448988c606cd6a1f451712",
        "_execution_state": "idle",
        "_cell_guid": "15f8fed4-bbf8-4eca-b400-8ea194010c78",
        "id": "LJWnRZGovMxt",
        "colab_type": "text"
      },
      "source": [
        "We add **XGBoost and LightGBM** to the** StackedRegressor** defined previously. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9015eddf85323209a7729420affecb9940bdd7d3",
        "_execution_state": "idle",
        "_cell_guid": "5ab5b13e-78c1-49be-9bcb-e54a6bf119d7",
        "id": "Ck9Du8VPvMxu",
        "colab_type": "text"
      },
      "source": [
        "We first define a rmsle evaluation function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "07f9ef433905b61a08a36790254d6a34661f0653",
        "_execution_state": "idle",
        "_cell_guid": "232c3959-c6e1-4535-8ad4-62892edc3f06",
        "trusted": true,
        "id": "dmU5iDFuvMxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmsle(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b7b74b70e6514b7623bc67cfec2b4f5d37c98707",
        "_execution_state": "idle",
        "_cell_guid": "999a8cc6-5083-4fca-bc90-616ac2f3ef8b",
        "id": "FzN-DhrZvMxx",
        "colab_type": "text"
      },
      "source": [
        "###Final Training and Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "115d9e90a84c33213f0f0de7d86b6098f29ca7d8",
        "_execution_state": "idle",
        "_cell_guid": "717b4b02-8bcf-4df3-8994-f6a113110115",
        "id": "9Sr2mhgpvMx7",
        "colab_type": "text"
      },
      "source": [
        "**StackedRegressor:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8936479533c4bb147ab09f1d2133d8bacbf9afc1",
        "_execution_state": "busy",
        "_cell_guid": "e64b2750-1e32-4e91-affb-e583d6ca8722",
        "trusted": true,
        "id": "OPiLPfyWvMyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_averaged_models.fit(train.values, y_train)\n",
        "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
        "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
        "print(rmsle(y_train, stacked_train_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "06a0eafc07a8dae002f3fc1499849ebf7ec014be",
        "_execution_state": "idle",
        "_cell_guid": "6c322757-44c0-4c81-a319-1aa6ccdf440f",
        "id": "eBc1QUiavMyG",
        "colab_type": "text"
      },
      "source": [
        "**XGBoost:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c80de2558910e4091f087a99bfcb202f01033ad7",
        "_execution_state": "idle",
        "_cell_guid": "2af45055-47aa-4e26-84df-ba5726bdff54",
        "trusted": true,
        "id": "1RivafVBvMyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_xgb.fit(train, y_train)\n",
        "xgb_train_pred = model_xgb.predict(train)\n",
        "xgb_pred = np.expm1(model_xgb.predict(test))\n",
        "print(rmsle(y_train, xgb_train_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b6d1cdcc2bfc08d0eb58135878008e6d64987089",
        "_execution_state": "idle",
        "_cell_guid": "22b2b135-2af8-4dbb-a8f0-1fcd7f745a66",
        "id": "unBCAXYSvMyK",
        "colab_type": "text"
      },
      "source": [
        "**LightGBM:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "65398376dca67e2aa78576108a0bb8160031c111",
        "_execution_state": "idle",
        "_cell_guid": "995d4c8e-db72-4370-a1ec-50e0c761f09a",
        "trusted": true,
        "id": "O-L5fEYrvMyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_lgb.fit(train, y_train)\n",
        "lgb_train_pred = model_lgb.predict(train)\n",
        "lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
        "print(rmsle(y_train, lgb_train_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "07500cf506f6a90c6439c2dabf81ab966cf1c792",
        "_execution_state": "idle",
        "_cell_guid": "619452b2-c395-48fe-81ab-d6b1d355236b",
        "trusted": true,
        "id": "nCQy942svMyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''RMSE on the entire Train data when averaging'''\n",
        "\n",
        "print('RMSLE score on train data:')\n",
        "print(rmsle(y_train,stacked_train_pred*0.70 +\n",
        "               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "59443e95f66cb9e595cff9a3666824299239126b",
        "_execution_state": "idle",
        "_cell_guid": "844b5e21-7bd2-4a2b-9f7a-2e755ed06ecb",
        "id": "9S_HKX3svMyS",
        "colab_type": "text"
      },
      "source": [
        "**Ensemble prediction:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "18996472b775bd9114fea7f08c8a554d4dafe774",
        "_execution_state": "idle",
        "_cell_guid": "3ec2c58f-6bee-46a6-a263-1fe2cf3569cb",
        "trusted": true,
        "id": "yV6PFM5gvMyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c9f02561da543f4901dcd2051acbd6c197108dd5",
        "_execution_state": "idle",
        "_cell_guid": "434ca649-2fa0-46a5-ab29-7f403448ddf7",
        "id": "fXCIBozfvMyW",
        "colab_type": "text"
      },
      "source": [
        "**Submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "93f6915cf25c7bb6b6fa6e74ad7b853387ac1db5",
        "_execution_state": "idle",
        "_cell_guid": "3db46af9-e18a-43bb-9699-45b851f835e5",
        "trusted": true,
        "id": "T2TlGvO2vMyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.DataFrame()\n",
        "sub['Id'] = test_ID\n",
        "sub['SalePrice'] = ensemble\n",
        "sub.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8a08ae030e55075f00e4f5d9354610c9b88c4c24",
        "_execution_state": "idle",
        "_cell_guid": "a35b0fbc-5235-4463-a86f-526a32b86956",
        "id": "MiTPtLeJvMyd",
        "colab_type": "text"
      },
      "source": [
        "**If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ARdUBSmevMyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}